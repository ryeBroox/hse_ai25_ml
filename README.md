# Выводы по домашке №1

## Всю работу можно поделить на следующие основные этапы:
1. EDA 
    В рамках EDA была выполнена первичная предобработка данных: удалили дубликаты, заполнили пропуски медианными значениями, обработали числовые признаки (убрали единицы измерения и оставили только сами значения) и сделали нужные преобразования типов для числовых признаков. В результате - данные готовы к использованию моделью.
2. Работа с моделями 
    В рамках этого этапа поработали с разными моделями, среди которых: линейная регрессия (на обычных признаках + на scaled признаках), Lasso-регрессия, ElasticNet, Ridge-регрессия (на scaled данных + категориальных фичах). Последние 3 модели также применяли в рамках GridSearch и искали лучшие гиперпараметры для них. Также оценили все модели на качество по метрикам: MSE (RMSE), R^2, бизнес-метрика
3. Деплой 
    В рамках деплоя сохранили лучшую модель в pickle и применили ее в рамках развернутого streamlit-приложения, в котором можно интерактивно работать с нашей моделью и признаками.

## Оценка моделей

Ниже приведена таблица с результатами по бизнес-мерике и R^2. По всем показателям выиграла регрессия с L2-регуляризацией, так как обобщая способность (R^2) у нее максимальная, так еще и по бизнес-метрике сильный прирост.

| Модель              | R2 train            | R2 test             | Business metric train | Business metric test |
|---------------------|---------------------|---------------------|-----------------------|----------------------|
| linreg              | 0.5927927865685232  | 0.616223383901233   | 0.21678082191780823   | 0.23093447905477982  |
| linreg_scaled       | 0.5927927865685246  | 0.6162233839012369  | 0.21678082191780823   | 0.23093447905477982  |
| lasso               | 0.592792786533488   | 0.6162229211779389  | 0.21678082191780823   | 0.23093447905477982  |
| lasso_best          | 0.5927468844825057  | 0.6156583794799229  | 0.21712328767123287   | 0.22341568206229862  |
| elastic_best        | 0.5927613343577207  | 0.6156105014436809  | 0.2183219178082192    | 0.22663802363050484  |
| **ridge_best**         | **0.6525027214162349** | **0.653908229621363** | 0.2089041095890411   | **0.2502685284640172** |

При анализе причин, которые повлияли на улучшение модели, выделяются следующие аспекты:
1. Стандартный скейлинг признаков погоды не сделал, точно так же как и L1-регуляризация. 
2. При подборе лучших гиперпараметров по сетке Lasso-регрессия оптимизировала MSE, и оно стало еле-еле лучше, но при этом по остальынм метрикам просела. 
3. При исползовании elastic версии получилась похожая история, так как обучались на оптимизации MSE 
4. Для Ridge регрессии сделали сразу несколько улучшений: добавили категориальные фичи + оптимизировались по r^2

В связи с этим сложно сказать, что дало наилучший прирост, так как потенциальных кандидатов на это сразу 3:
1. Добавление категориальных фичей
2. использование Ridge-регрессии
3. Оптимизация по R^2

## Что сделать не удалось
Во-первых, не удалось как раз определиться с тем, какое улучшение все-таки внесло наибольший импакт, потому что для этого понадобилось еще несколько вариаций модели и ее обучение.
Во-вторых, некоторые из признаков все же удалили (например, name), так как его предобработка (хорошего качества) сложная. Однако я уверен, что это дало бы хороший буст к качеству, так как можно было бы выделять и модель, и конкретную марку, а бренд всегда влияет на то, сколько стоит товар. 

## Оценка сервиса с Streamlit
Приложение достаточно удобно, так как грузишь файл с исходными признаками - и получаешь сразу информацию по распределениям и корреляциям для нужных признаков + сводку по матрице корреляций. Далее для каждого объекта можно посмотреть, какая у него цена предсказанная модель и какие параметры. Интерактивность в этом плане получилась удобной.
Про визуализации - так как я разрулил через селектор, то графики по распределениям и корреляциям довольно удобны (для числовых признаков). Для категориальных визуализаций нет, поэтому можно сказать, что с ними получилось не очень, это и является одной из проблем сервиса, которую можно исправить в следующую итерацию. Также одной из проблем является то, что в значениях признаках могут добавиться новые кейсы (например, новые единицы измерения), и тогда логика его обработки будет нарушена. На следующие итерации можно следить за загружаемыми данными и получать новые инсайты про то, какие еще кейсы встречаются и что стоит дополнительно учесть в предобработке признаков.